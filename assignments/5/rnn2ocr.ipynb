{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### 4 RNN","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nnp.random.seed(42)\nimport nltk\nfrom nltk.corpus import words\nfrom PIL import Image, ImageDraw, ImageFont\n\nimport os\nimport sys\n\nproject_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\nsys.path.append(project_root)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:05:08.618865Z","iopub.execute_input":"2024-11-18T18:05:08.619459Z","iopub.status.idle":"2024-11-18T18:05:13.815430Z","shell.execute_reply.started":"2024-11-18T18:05:08.619424Z","shell.execute_reply":"2024-11-18T18:05:13.814781Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"#### 4.2 Optical Character Recognition","metadata":{}},{"cell_type":"markdown","source":"##### 4.2.1 Task 1: Dataset","metadata":{}},{"cell_type":"code","source":"nltk.download('words')\nword_list = words.words()\n\nimport random\n# Randomly sample 100k words\ndataset_words = random.sample(word_list, 100000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:05:37.335879Z","iopub.execute_input":"2024-11-18T18:05:37.336565Z","iopub.status.idle":"2024-11-18T18:05:37.406347Z","shell.execute_reply.started":"2024-11-18T18:05:37.336530Z","shell.execute_reply":"2024-11-18T18:05:37.405514Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package words to /usr/share/nltk_data...\n[nltk_data]   Package words is already up-to-date!\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"os.makedirs('word_images', exist_ok=True)\n\n# Create a font object\n# font = ImageFont.truetype(\"arial.ttf\", 24)\nfont = ImageFont.load_default()\n\n# Generate images\nfor idx, word in enumerate(dataset_words):\n    img = Image.new('RGB', (256, 64), color = 'white')\n    d = ImageDraw.Draw(img)\n    # text_width, text_height = d.textsize(word, font=font)\n    text_bbox = d.textbbox((0, 0), word, font=font)\n    text_x = (256 - (text_bbox[2] - text_bbox[0])) // 2\n    text_y = (64 - (text_bbox[3] - text_bbox[1])) // 2\n    d.text((text_x, text_y), word, fill='black', font=font)\n    img.save(f'word_images/{word}_{idx}.png')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:05:41.837273Z","iopub.execute_input":"2024-11-18T18:05:41.837599Z","iopub.status.idle":"2024-11-18T18:05:42.791402Z","shell.execute_reply.started":"2024-11-18T18:05:41.837572Z","shell.execute_reply":"2024-11-18T18:05:42.790554Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import pandas as pd\n\n# Create a DataFrame with image paths and labels\ndata = {'image_path': [f'word_images/{word}_{i}.png' for i, word in enumerate(dataset_words)],\n        'label': dataset_words}\ndf = pd.DataFrame(data)\n\n# Save to a CSV file\ndf.to_csv('word_dataset.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:05:43.603328Z","iopub.execute_input":"2024-11-18T18:05:43.603876Z","iopub.status.idle":"2024-11-18T18:05:44.370914Z","shell.execute_reply.started":"2024-11-18T18:05:43.603841Z","shell.execute_reply":"2024-11-18T18:05:44.369989Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Load the dataset\ndata = pd.read_csv('word_dataset.csv')\n\n# Split into train (80%), val (10%), test (10%)\ntrain, test = train_test_split(data, test_size=0.2, random_state=42)\nval, test = train_test_split(test, test_size=0.5, random_state=42)\n\n# Save the splits\ntrain.to_csv('train.csv', index=False)\nval.to_csv('val.csv', index=False)\ntest.to_csv('test.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:05:45.418081Z","iopub.execute_input":"2024-11-18T18:05:45.418747Z","iopub.status.idle":"2024-11-18T18:05:45.438165Z","shell.execute_reply.started":"2024-11-18T18:05:45.418714Z","shell.execute_reply":"2024-11-18T18:05:45.437555Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def display_samples(sample_dir, num_samples=2):\n    # Get the list of image file paths\n    sample_files = os.listdir(sample_dir)\n    sample_files = random.sample(sample_files, num_samples)\n    \n    # Display the images\n    fig, axes = plt.subplots(1, num_samples, figsize=(12, 4))\n    for i, sample_file in enumerate(sample_files):\n        img_path = os.path.join(sample_dir, sample_file)\n        img = Image.open(img_path)\n        axes[i].imshow(img)\n        axes[i].axis()\n        axes[i].set_title(sample_file.split('.')[0])\n    plt.tight_layout()\n    plt.show()\n    \ndisplay_samples('word_images')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:05:47.221558Z","iopub.execute_input":"2024-11-18T18:05:47.221907Z","iopub.status.idle":"2024-11-18T18:05:47.667575Z","shell.execute_reply.started":"2024-11-18T18:05:47.221877Z","shell.execute_reply":"2024-11-18T18:05:47.666698Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x400 with 2 Axes>","image/png":"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"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"##### 4.2.2 Task 2: Architecture","metadata":{}},{"cell_type":"code","source":"class CNNEncoder(nn.Module):\n    def __init__(self):\n        super(CNNEncoder, self).__init__()\n        self.features = nn.Sequential(\n            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(64),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(128),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(inplace=True),\n            nn.BatchNorm2d(256),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            \n            nn.Dropout2d(0.2)\n        )\n        \n    def forward(self, x):\n        x = self.features(x)\n        batch_size = x.size(0)\n        x = x.permute(0, 2, 3, 1)\n        x = x.contiguous().view(batch_size, -1, 256)\n        return x\n    \nclass RNNDecoder(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n        super(RNNDecoder, self).__init__()\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        \n        self.embedding = nn.Embedding(output_size, hidden_size)\n        self.rnn = nn.RNN(hidden_size + input_size, hidden_size, n_layers,\n                         batch_first=True, dropout=0.2 if n_layers > 1 else 0)\n        self.out = nn.Linear(hidden_size, output_size)\n        \n    def forward(self, encoder_outputs, target, hidden=None):\n        batch_size = encoder_outputs.size(0)\n        max_length = target.size(1)\n        \n        outputs = torch.zeros(batch_size, max_length, self.output_size).to(encoder_outputs.device)\n        \n        embedded = self.embedding(target)\n        \n        # Initialize hidden state if not provided\n        if hidden is None:\n            hidden = torch.zeros(1, batch_size, self.hidden_size).to(encoder_outputs.device)\n        \n        # For each time step\n        for t in range(max_length):\n            context = encoder_outputs[:, t:t+1, :]\n            \n            rnn_input = torch.cat((embedded[:, t:t+1, :], context), dim=2)     \n            \n            output, hidden = self.rnn(rnn_input, hidden)\n            \n            output = self.out(output.squeeze(1))\n            outputs[:, t] = output\n            \n        return outputs, hidden\n    \nclass OCRModel(nn.Module):\n    def __init__(self, vocab_size, hidden_size=256):\n        super(OCRModel, self).__init__()\n        self.encoder = CNNEncoder()\n        self.decoder = RNNDecoder(input_size=256, hidden_size=hidden_size, output_size=vocab_size)\n    \n    def forward(self, images, target=None, target_length=None):\n        batch_size = images.size(0)\n        encoder_outputs = self.encoder(images)\n        \n        if self.training and target is not None:\n            outputs, _ = self.decoder(encoder_outputs, target, hidden=None)\n            return outputs\n        else:\n            # Inference mode\n            max_length = target_length.max().item() if target_length is not None else 25  # Maximum sequence length\n            outputs = torch.zeros(batch_size, max_length, self.decoder.output_size).to(images.device)\n            \n            # Initialize with <sos>\n            decoder_input = torch.ones(batch_size, 1).long().to(images.device) * 27  # <sos> token\n            hidden = None\n            \n            for t in range(max_length):\n                out, hidden = self.decoder(encoder_outputs, decoder_input, hidden)\n                outputs[:, t:t+1] = out\n                # Get the most likely next character\n                _, topi = out.max(2)\n                decoder_input = topi.squeeze(-1).unsqueeze(1)\n                \n                # Stop if all sequences have generated <eos>\n                if (decoder_input == 28).all():  # 28 is <eos> token\n                    break\n            \n            return outputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:05:50.244819Z","iopub.execute_input":"2024-11-18T18:05:50.245593Z","iopub.status.idle":"2024-11-18T18:05:50.260357Z","shell.execute_reply.started":"2024-11-18T18:05:50.245558Z","shell.execute_reply":"2024-11-18T18:05:50.259523Z"}},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"##### 4.2.3 Task 3: Training","metadata":{}},{"cell_type":"code","source":"class WordImageDataset(Dataset):\n    def __init__(self, csv_file, img_dir, transform=None, max_length=20):\n        self.data = pd.read_csv(csv_file)\n        self.img_dir = img_dir\n        self.transform = transform\n        self.max_length = max_length\n        \n        # Create a character to index mapping\n        self.char_to_idx = {chr(i): i-97 for i in range(97, 123)}  # a-z\n        self.char_to_idx['<pad>'] = 26\n        self.char_to_idx['<sos>'] = 27\n        self.char_to_idx['<eos>'] = 28\n        self.idx_to_char = {v: k for k, v in self.char_to_idx.items()}\n        self.vocab_size = len(self.char_to_idx)\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.data.iloc[idx]['image_path'])\n        image = Image.open(img_path).convert('L')  # Convert to grayscale\n        # word = self.data.iloc[idx]['label'].lower()\n\n        # # Handle missing or non-string labels\n        word = self.data.iloc[idx]['label']\n        if not isinstance(word, str):\n            word = str(word)\n        word = word.lower()\n\n        if self.transform:\n            image = self.transform(image)\n\n        # Convert word to indices\n        target = [self.char_to_idx['<sos>']]\n        target.extend([self.char_to_idx[c] for c in self.char_to_idx])\n        # try:\n        #     target.extend([self.char_to_idx[c] for c in word if c in self.char_to_idx])\n        # except KeyError:\n        #     print(f\"Encountered unknown character in word: {word}\")\n        target.append(self.char_to_idx['<eos>'])\n        \n        length = len(target)\n        \n        # Pad sequence if necessary\n        while length < self.max_length:\n            target.extend([self.char_to_idx['<pad>']] * (self.max_length - length))\n        else:\n            target = target[:self.max_length]\n            length = self.max_length\n        \n        return image, torch.tensor(target), length","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:05:55.110496Z","iopub.execute_input":"2024-11-18T18:05:55.110798Z","iopub.status.idle":"2024-11-18T18:05:55.119553Z","shell.execute_reply.started":"2024-11-18T18:05:55.110773Z","shell.execute_reply":"2024-11-18T18:05:55.118779Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def collate_fn(batch):\n    \"\"\"\n    Custom collate function to handle variable length sequences\n    \"\"\"\n    # Sort batch by sequence length (descending)\n    batch.sort(key=lambda x: x[2], reverse=True)\n    \n    # Separate images, targets, and lengths\n    images, targets, lengths = zip(*batch)\n    \n    # Stack images\n    images = torch.stack(images, 0)\n    \n    # Pad and stack targets\n    targets = torch.stack(targets, 0)\n    \n    # Convert lengths to tensor\n    lengths = torch.tensor(lengths)\n    \n    return images, targets, lengths\n\ndef setup_training(batch_size=32):\n    \"\"\"\n    Set up datasets and dataloaders for training\n    \"\"\"\n    # Define transforms\n    transform = transforms.Compose([\n        transforms.Resize((64, 256)),\n        transforms.ToTensor(),\n    ])\n\n    img_dir = '/kaggle/working/'\n    # Create datasets\n    train_dataset = WordImageDataset('train.csv', img_dir, transform=transform)\n    val_dataset = WordImageDataset('val.csv', img_dir, transform=transform)\n    test_dataset = WordImageDataset('test.csv',img_dir,transform=transform)\n\n    # Create dataloaders with custom collate function\n    train_loader = DataLoader(\n        train_dataset, \n        batch_size=batch_size, \n        shuffle=True,\n        collate_fn=collate_fn,\n        num_workers=4,\n        pin_memory=True\n    )\n    \n    val_loader = DataLoader(\n        val_dataset, \n        batch_size=batch_size,\n        collate_fn=collate_fn,\n        num_workers=4,\n        pin_memory=True\n    )\n\n    test_loader = DataLoader(\n        test_dataset, \n        batch_size=batch_size,\n        collate_fn=collate_fn,\n        num_workers=4,\n        pin_memory=True\n    )\n\n    return train_loader, val_loader, test_loader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:05:58.210605Z","iopub.execute_input":"2024-11-18T18:05:58.210929Z","iopub.status.idle":"2024-11-18T18:05:58.217859Z","shell.execute_reply.started":"2024-11-18T18:05:58.210901Z","shell.execute_reply":"2024-11-18T18:05:58.217095Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Training function\ndef train_epoch(model, train_loader, criterion, optimizer, device):\n    model.train()\n    total_loss = 0\n    correct_chars = 0\n    total_chars = 0\n    \n    for batch_idx, (images, targets, lengths) in enumerate(train_loader):\n        images, targets = images.to(device), targets.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(images, targets, lengths)\n        \n        # Reshape outputs and targets for loss calculation\n        batch_size = outputs.size(0)\n        outputs = outputs.view(-1, outputs.size(2))\n        targets = targets.view(-1)\n        \n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        \n        # Calculate accuracy\n        pred = outputs.argmax(dim=1)\n        mask = targets != 26  # Ignore padding token\n        correct_chars += ((pred == targets) & mask).sum().item()\n        total_chars += mask.sum().item()\n        \n        # if batch_idx % 100 == 0:\n        #     print(f'Batch {batch_idx}: Loss {loss.item():.4f}, Acc {correct_chars/total_chars:.4f}')\n        \n    return total_loss / len(train_loader), correct_chars / total_chars\n\n# Validation function\ndef validate(model, val_loader, criterion, device):\n    model.eval()\n    total_loss = 0\n    correct_chars = 0\n    total_chars = 0\n    \n    with torch.no_grad():\n        for batch_idx, (images, targets, lengths) in enumerate(val_loader):\n\n            images, targets = images.to(device), targets.to(device)\n            \n            outputs = model(images, targets, lengths)\n            # outputs = model(images, target=None, target_length=lengths)\n\n            # Reshape outputs and targets for loss calculation\n            batch_size = outputs.size(0)\n            outputs = outputs.view(-1, outputs.size(2))\n            targets = targets.view(-1)\n                    \n            loss = criterion(outputs, targets)\n            total_loss += loss.item()\n\n            # Calculate accuracy\n            pred = outputs.argmax(dim=1)\n            mask = targets != 26  # Ignore padding token\n            correct_chars += ((pred == targets) & mask).sum().item()\n            total_chars += mask.sum().item()\n            \n            # # Calculate accuracy\n            # pred = outputs.argmax(dim=1)\n            # correct_chars += (pred == targets).sum().item()\n            # total_chars += targets.size(0)\n    \n    return total_loss / len(val_loader), correct_chars / total_chars","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:06:02.035437Z","iopub.execute_input":"2024-11-18T18:06:02.036147Z","iopub.status.idle":"2024-11-18T18:06:02.045944Z","shell.execute_reply.started":"2024-11-18T18:06:02.036113Z","shell.execute_reply":"2024-11-18T18:06:02.044930Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Main training loop\ndef train_model(model, train_loader, val_loader, num_epochs=5, device='cuda'):\n    criterion = nn.CrossEntropyLoss(ignore_index=26)  # ignore padding index\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=2)\n    \n    best_val_acc = 0\n    for epoch in range(num_epochs):\n        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n        val_loss, val_acc = validate(model, val_loader, criterion, device)\n\n        scheduler.step(val_loss)\n        \n        print(f'Epoch {epoch+1}/{num_epochs}:')\n        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}')\n        \n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), 'best_model.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:06:05.496839Z","iopub.execute_input":"2024-11-18T18:06:05.497709Z","iopub.status.idle":"2024-11-18T18:06:05.503659Z","shell.execute_reply.started":"2024-11-18T18:06:05.497672Z","shell.execute_reply":"2024-11-18T18:06:05.502712Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# project_root = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Setup data loaders\ntrain_loader, val_loader, test_loader = setup_training()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:06:08.092422Z","iopub.execute_input":"2024-11-18T18:06:08.093073Z","iopub.status.idle":"2024-11-18T18:06:08.157273Z","shell.execute_reply.started":"2024-11-18T18:06:08.093024Z","shell.execute_reply":"2024-11-18T18:06:08.156428Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Initialize model\nmodel = OCRModel(vocab_size=29).to(device)\n\n# Train model\ntrain_model(model, train_loader, val_loader, device=device)","metadata":{"execution":{"iopub.status.busy":"2024-11-18T18:12:54.230354Z","iopub.execute_input":"2024-11-18T18:12:54.230686Z","iopub.status.idle":"2024-11-18T18:12:54.235896Z","shell.execute_reply.started":"2024-11-18T18:12:54.230657Z","shell.execute_reply":"2024-11-18T18:12:54.234945Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch 1/5:\nTrain Loss: 0.6465, Train Acc: 0.9194\nVal Loss: 0.0005, Val Acc: 0.9090\nEpoch 2/5:\nTrain Loss: 0.0067, Train Acc: 1.0000\nVal Loss: 0.0002, Val Acc: 0.9999\nEpoch 3/5:\nTrain Loss: 0.0035, Train Acc: 1.0000\nVal Loss: 0.0001, Val Acc: 1.0000\nEpoch 4/5:\nTrain Loss: 0.0027, Train Acc: 1.0000\nVal Loss: 0.0000, Val Acc: 1.0000\nEpoch 5/5:\nTrain Loss: 0.0024, Train Acc: 1.0000\nVal Loss: 0.0000, Val Acc: 1.0000\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss(ignore_index=26)\ntest_loss, test_accuracy = validate(model,test_loader,criterion,device)\nprint(f\"Test Accuracy: {test_accuracy}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:15:10.432958Z","iopub.execute_input":"2024-11-18T18:15:10.433887Z","iopub.status.idle":"2024-11-18T18:15:10.438570Z","shell.execute_reply.started":"2024-11-18T18:15:10.433847Z","shell.execute_reply":"2024-11-18T18:15:10.437659Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 0.9998\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"def generate_random_baseline(batch_size, max_length, num_classes):\n    return torch.randint(1, num_classes, (batch_size, max_length))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:17:59.238955Z","iopub.execute_input":"2024-11-18T18:17:59.239349Z","iopub.status.idle":"2024-11-18T18:17:59.243948Z","shell.execute_reply.started":"2024-11-18T18:17:59.239317Z","shell.execute_reply":"2024-11-18T18:17:59.242971Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# Find average number of correct characters on test set using random baseline\ntotal_correct = 0\ntotal_characters = 0\n\nfor images, labels, _ in test_loader:\n    true_word = labels[0]  # Flatten the true word\n    pred = generate_random_baseline(1, true_word.size(0), num_classes=27)  # Random prediction\n    correct_characters = (true_word == pred).sum().item()\n    total_correct += correct_characters\n    total_characters += len(true_word)\n\nrandom_baseline_accuracy = total_correct / total_characters if total_characters > 0 else 0\nprint(f\"Random Baseline Accuracy: {random_baseline_accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:18:58.915535Z","iopub.execute_input":"2024-11-18T18:18:58.915867Z","iopub.status.idle":"2024-11-18T18:18:59.108988Z","shell.execute_reply.started":"2024-11-18T18:18:58.915839Z","shell.execute_reply":"2024-11-18T18:18:59.107916Z"}},"outputs":[{"name":"stdout","text":"Random Baseline Accuracy: 0.0125\n","output_type":"stream"}],"execution_count":39}]}